{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-11-12T08:25:48.760608Z",
          "iopub.status.busy": "2025-11-12T08:25:48.759765Z"
        },
        "id": "5pzW83gwRJl3",
        "outputId": "1b05952d-f593-423f-f903-17c9d87b3742",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Detected task: classification\n",
            "\n",
            "========================================\n",
            "Training model: LogisticRegression\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=25. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train scores for LogisticRegression: {'accuracy': 0.8080808080808081, 'f1_weighted': 0.806710661578735, 'roc_auc': np.float64(0.8617955027215886)}\n",
            "Best hyperparameters:\n",
            "  model__penalty: l2\n",
            "  model__C: 10\n",
            "Test predictions saved to submission_LogisticRegression.csv\n",
            "\n",
            "========================================\n",
            "Training model: DecisionTreeClassifier\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 12 is smaller than n_iter=25. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train scores for DecisionTreeClassifier: {'accuracy': 0.8282828282828283, 'f1_weighted': 0.825898782631449, 'roc_auc': np.float64(0.863284121049436)}\n",
            "Best hyperparameters:\n",
            "  model__min_samples_split: 2\n",
            "  model__max_depth: 3\n",
            "Top feature importances:\n",
            " low_card__Sex_female    0.621440\n",
            "num__Pclass             0.155642\n",
            "high_card__Ticket       0.062216\n",
            "num__Age                0.057095\n",
            "num__Fare               0.050200\n",
            "num__SibSp              0.044395\n",
            "high_card__Name         0.009012\n",
            "num__PassengerId        0.000000\n",
            "num__Parch              0.000000\n",
            "low_card__Sex_male      0.000000\n",
            "low_card__Embarked_Q    0.000000\n",
            "low_card__Embarked_C    0.000000\n",
            "low_card__Embarked_S    0.000000\n",
            "high_card__Cabin        0.000000\n",
            "dtype: float64\n",
            "Test predictions saved to submission_DecisionTreeClassifier.csv\n",
            "\n",
            "========================================\n",
            "Training model: RandomForestClassifier\n",
            "Train scores for RandomForestClassifier: {'accuracy': 1.0, 'f1_weighted': 1.0, 'roc_auc': np.float64(1.0)}\n",
            "Best hyperparameters:\n",
            "  model__n_estimators: 300\n",
            "  model__min_samples_split: 2\n",
            "  model__max_depth: None\n",
            "Top feature importances:\n",
            " low_card__Sex_male      0.132702\n",
            "low_card__Sex_female    0.130546\n",
            "high_card__Ticket       0.129449\n",
            "num__Fare               0.115496\n",
            "high_card__Name         0.107317\n",
            "num__Age                0.100967\n",
            "num__PassengerId        0.098763\n",
            "num__Pclass             0.060114\n",
            "high_card__Cabin        0.045926\n",
            "num__SibSp              0.029407\n",
            "num__Parch              0.022382\n",
            "low_card__Embarked_S    0.011436\n",
            "low_card__Embarked_C    0.009719\n",
            "low_card__Embarked_Q    0.005777\n",
            "dtype: float64\n",
            "Test predictions saved to submission_RandomForestClassifier.csv\n",
            "\n",
            "========================================\n",
            "Training model: XGBClassifier\n",
            "Train scores for XGBClassifier: {'accuracy': 0.8742985409652076, 'f1_weighted': 0.8723991225742539, 'roc_auc': np.float64(0.9290895727478987)}\n",
            "Best hyperparameters:\n",
            "  model__n_estimators: 100\n",
            "  model__max_depth: 3\n",
            "  model__learning_rate: 0.05\n",
            "Top feature importances:\n",
            " low_card__Sex_female    0.455251\n",
            "num__Pclass             0.152362\n",
            "num__SibSp              0.065967\n",
            "low_card__Embarked_S    0.049678\n",
            "num__Age                0.046884\n",
            "num__Fare               0.046408\n",
            "high_card__Ticket       0.044748\n",
            "high_card__Cabin        0.043364\n",
            "low_card__Embarked_C    0.040798\n",
            "num__PassengerId        0.031762\n",
            "high_card__Name         0.022778\n",
            "num__Parch              0.000000\n",
            "low_card__Embarked_Q    0.000000\n",
            "low_card__Sex_male      0.000000\n",
            "dtype: float32\n",
            "Test predictions saved to submission_XGBClassifier.csv\n",
            "\n",
            "========================================\n",
            "Training model: LGBMClassifier\n",
            "[LightGBM] [Info] Number of positive: 342, number of negative: 549\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1057\n",
            "[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288\n",
            "[LightGBM] [Info] Start training from score -0.473288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train scores for LGBMClassifier: {'accuracy': 0.9259259259259259, 'f1_weighted': 0.9254226010645951, 'roc_auc': np.float64(0.9853588129400611)}\n",
            "Best hyperparameters:\n",
            "  model__num_leaves: 50\n",
            "  model__n_estimators: 300\n",
            "  model__learning_rate: 0.01\n",
            "Top feature importances:\n",
            " high_card__Name         2099\n",
            "high_card__Ticket       2028\n",
            "num__PassengerId        1777\n",
            "num__Fare               1746\n",
            "num__Age                1431\n",
            "num__Pclass              332\n",
            "low_card__Sex_female     295\n",
            "high_card__Cabin         247\n",
            "num__SibSp               195\n",
            "low_card__Embarked_C     105\n",
            "low_card__Embarked_S      79\n",
            "num__Parch                54\n",
            "low_card__Sex_male         8\n",
            "low_card__Embarked_Q       3\n",
            "dtype: int32\n",
            "Test predictions saved to submission_LGBMClassifier.csv\n",
            "\n",
            "========================================\n",
            "Training model: CatBoostClassifier\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train scores for CatBoostClassifier: {'accuracy': 0.9147025813692481, 'f1_weighted': 0.9138804927405357, 'roc_auc': np.float64(0.9567421894140329)}\n",
            "Best hyperparameters:\n",
            "  model__learning_rate: 0.1\n",
            "  model__iterations: 100\n",
            "  model__depth: 8\n",
            "Top feature importances:\n",
            " low_card__Sex_female    24.972550\n",
            "low_card__Sex_male      16.227276\n",
            "num__Pclass             11.193541\n",
            "high_card__Ticket        8.958246\n",
            "num__Age                 8.765641\n",
            "num__Fare                7.570820\n",
            "high_card__Name          7.205843\n",
            "num__PassengerId         6.183712\n",
            "high_card__Cabin         2.866396\n",
            "num__SibSp               2.448261\n",
            "low_card__Embarked_C     1.167143\n",
            "num__Parch               1.156842\n",
            "low_card__Embarked_S     1.121396\n",
            "low_card__Embarked_Q     0.162332\n",
            "dtype: float64\n",
            "Test predictions saved to submission_CatBoostClassifier.csv\n",
            "\n",
            "All models finished in 5.13 minutes\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "AutoML pipeline for Kaggle (train + test prediction)\n",
        "\n",
        "- Handles numeric and categorical features automatically\n",
        "- Trains multiple models, finds best hyperparameters\n",
        "- Predicts on provided test.csv and outputs submission.csv\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import joblib\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error, r2_score\n",
        "\n",
        "# Gradient boosting libraries\n",
        "HAS_XGB = HAS_LGB = HAS_CAT = False\n",
        "try: from xgboost import XGBClassifier, XGBRegressor; HAS_XGB = True\n",
        "except: pass\n",
        "try: from lightgbm import LGBMClassifier, LGBMRegressor; HAS_LGB = True\n",
        "except: pass\n",
        "try: from catboost import CatBoostClassifier, CatBoostRegressor; HAS_CAT = True\n",
        "except: pass\n",
        "!pip install catboost\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# ------------------- Utilities -------------------\n",
        "\n",
        "def detect_task(y_series):\n",
        "    if y_series.dtype.name in ['object', 'category']:\n",
        "        return 'classification'\n",
        "    unique = y_series.nunique(dropna=True)\n",
        "    if np.issubdtype(y_series.dtype, np.integer) and unique <= 20:\n",
        "        return 'classification'\n",
        "    return 'regression'\n",
        "\n",
        "def score_function(task, y_true, y_pred, y_proba=None):\n",
        "    if task == 'classification':\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "        auc = None\n",
        "        if y_proba is not None and len(np.unique(y_true)) == 2:\n",
        "            try: auc = roc_auc_score(y_true, y_proba[:,1])\n",
        "            except: pass\n",
        "        return {'accuracy': acc, 'f1_weighted': f1, 'roc_auc': auc}\n",
        "    else:\n",
        "        mse = mean_squared_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "        return {'rmse': rmse, 'mse': mse, 'r2': r2}\n",
        "\n",
        "# ------------------- Preprocessor -------------------\n",
        "\n",
        "def build_preprocessor(X, max_onehot_levels=12):\n",
        "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    low_card_cols = [c for c in cat_cols if X[c].nunique(dropna=True) <= max_onehot_levels]\n",
        "    high_card_cols = [c for c in cat_cols if c not in low_card_cols]\n",
        "\n",
        "    numeric_transformer = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    low_card_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "    high_card_transformer = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "    ])\n",
        "\n",
        "    transformers = []\n",
        "    if numeric_cols: transformers.append(('num', numeric_transformer, numeric_cols))\n",
        "    if low_card_cols: transformers.append(('low_card', low_card_transformer, low_card_cols))\n",
        "    if high_card_cols: transformers.append(('high_card', high_card_transformer, high_card_cols))\n",
        "\n",
        "    return ColumnTransformer(transformers=transformers, remainder='drop', sparse_threshold=0)\n",
        "    import warnings\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "# ------------------- Models & Hyperparameter Spaces -------------------\n",
        "def get_models_and_spaces(task):\n",
        "    models = {}\n",
        "    if task == 'regression':\n",
        "        models['LinearRegression'] = {'model': LinearRegression(), 'space': {}}\n",
        "        models['DecisionTreeRegressor'] = {'model': DecisionTreeRegressor(random_state=RANDOM_STATE),\n",
        "                                           'space': {'model__max_depth': [None, 3, 5, 10, 20],\n",
        "                                                     'model__min_samples_split': [2, 5, 10, 20]}}\n",
        "        models['RandomForestRegressor'] = {'model': RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "                                           'space': {'model__n_estimators': [100, 200, 500],\n",
        "                                                     'model__max_depth': [None, 5, 10, 20],\n",
        "                                                     'model__min_samples_split': [2, 5, 10]}}\n",
        "        if HAS_XGB:\n",
        "            models['XGBRegressor'] = {'model': XGBRegressor(random_state=RANDOM_STATE, n_jobs=-1, verbosity=0),\n",
        "                                      'space': {'model__n_estimators': [100, 300, 500],\n",
        "                                                'model__max_depth': [3, 5, 8],\n",
        "                                                'model__learning_rate': [0.01, 0.05, 0.1]}}\n",
        "        if HAS_LGB:\n",
        "            models['LGBMRegressor'] = {'model': LGBMRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "                                       'space': {'model__n_estimators': [100, 300, 500],\n",
        "                                                 'model__num_leaves': [31, 50, 100],\n",
        "                                                 'model__learning_rate': [0.01, 0.05, 0.1]}}\n",
        "        if HAS_CAT:\n",
        "            models['CatBoostRegressor'] = {'model': CatBoostRegressor(random_state=RANDOM_STATE, verbose=0),\n",
        "                                           'space': {'model__iterations': [100, 300, 500],\n",
        "                                                     'model__depth': [4, 6, 8],\n",
        "                                                     'model__learning_rate': [0.01, 0.05, 0.1]}}\n",
        "    else:\n",
        "        models['LogisticRegression'] = {'model': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
        "                                        'space': {'model__C': [0.01, 0.1, 1, 10],\n",
        "                                                  'model__penalty': ['l2']}}\n",
        "        models['DecisionTreeClassifier'] = {'model': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "                                            'space': {'model__max_depth': [None, 3, 5, 10],\n",
        "                                                      'model__min_samples_split': [2, 5, 10]}}\n",
        "        models['RandomForestClassifier'] = {'model': RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "                                            'space': {'model__n_estimators': [100, 300, 500],\n",
        "                                                      'model__max_depth': [None, 5, 10, 20],\n",
        "                                                      'model__min_samples_split': [2, 5, 10]}}\n",
        "        if HAS_XGB:\n",
        "            models['XGBClassifier'] = {'model': XGBClassifier(random_state=RANDOM_STATE, use_label_encoder=False, verbosity=0, n_jobs=-1),\n",
        "                                       'space': {'model__n_estimators': [100, 300, 500],\n",
        "                                                 'model__max_depth': [3, 5, 8],\n",
        "                                                 'model__learning_rate': [0.01, 0.05, 0.1]}}\n",
        "        if HAS_LGB:\n",
        "            models['LGBMClassifier'] = {'model': LGBMClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "                                        'space': {'model__n_estimators': [100, 300, 500],\n",
        "                                                  'model__num_leaves': [31, 50, 100],\n",
        "                                                  'model__learning_rate': [0.01, 0.05, 0.1]}}\n",
        "        if HAS_CAT:\n",
        "            models['CatBoostClassifier'] = {'model': CatBoostClassifier(random_state=RANDOM_STATE, verbose=0),\n",
        "                                            'space': {'model__iterations': [100, 300, 500],\n",
        "                                                      'model__depth': [4, 6, 8],\n",
        "                                                      'model__learning_rate': [0.01, 0.05, 0.1]}}\n",
        "    return models\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ------------------- Main AutoML Runner -------------------\n",
        "\n",
        "def run_auto_ml(train_df, test_df=None, target_col=None, n_iter_search=25, cv_folds=5, max_onehot_levels=12):\n",
        "    start_time = time.time()\n",
        "\n",
        "    if target_col is None:\n",
        "        for candidate in ['target','TARGET','label','y','Survived']:\n",
        "            if candidate in train_df.columns: target_col = candidate; break\n",
        "        if target_col is None: raise ValueError(\"Provide target column name.\")\n",
        "\n",
        "    X_train = train_df.drop(columns=[target_col])\n",
        "    y_train = train_df[target_col]\n",
        "    task = detect_task(y_train)\n",
        "    print(f\"Detected task: {task}\")\n",
        "\n",
        "    # Combine train + test for preprocessing if test_df is provided\n",
        "    if test_df is not None:\n",
        "        combined = pd.concat([X_train, test_df], axis=0)\n",
        "    else:\n",
        "        combined = X_train.copy()\n",
        "\n",
        "    preprocessor = build_preprocessor(combined, max_onehot_levels=max_onehot_levels)\n",
        "    models_spaces = get_models_and_spaces(task)\n",
        "    results = []\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_STATE) if task=='classification' else KFold(n_splits=cv_folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "    scoring = 'accuracy' if task=='classification' else 'neg_root_mean_squared_error'\n",
        "\n",
        "    for name,cfg in models_spaces.items():\n",
        "        print('\\n'+'='*40)\n",
        "        print(f\"Training model: {name}\")\n",
        "        pipe = Pipeline([('preprocessor', preprocessor), ('model', cfg['model'])])\n",
        "        param_space = cfg.get('space', {})\n",
        "\n",
        "        if param_space:\n",
        "            search = RandomizedSearchCV(pipe, param_distributions=param_space, n_iter=min(n_iter_search,50),\n",
        "                                        cv=cv, scoring=scoring, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "            search.fit(X_train,y_train)\n",
        "            best = search.best_estimator_\n",
        "            best_params = search.best_params_\n",
        "        else:\n",
        "            pipe.fit(X_train,y_train)\n",
        "            best = pipe\n",
        "            best_params = {}\n",
        "\n",
        "        # Evaluate on training data\n",
        "        y_train_pred = best.predict(X_train)\n",
        "        y_train_proba = None\n",
        "        try:\n",
        "            if task=='classification' and hasattr(best.named_steps['model'],'predict_proba'):\n",
        "                y_train_proba = best.predict_proba(X_train)\n",
        "        except: pass\n",
        "        train_scores = score_function(task, y_train, y_train_pred, y_train_proba)\n",
        "\n",
        "        # Feature importances\n",
        "        feature_importances = None\n",
        "        try:\n",
        "            m = best.named_steps['model']\n",
        "            if hasattr(m,'feature_importances_'):\n",
        "                X_trans = best.named_steps['preprocessor'].transform(X_train)\n",
        "                feature_names = best.named_steps['preprocessor'].get_feature_names_out() if hasattr(best.named_steps['preprocessor'],'get_feature_names_out') else X_train.columns\n",
        "                fi = pd.Series(m.feature_importances_, index=feature_names)\n",
        "                feature_importances = fi.sort_values(ascending=False).head(20)\n",
        "        except: pass\n",
        "\n",
        "        results.append({'model': name, 'best_params': best_params,\n",
        "                        'train_scores': train_scores,\n",
        "                        'feature_importances': feature_importances})\n",
        "\n",
        "        joblib.dump(best,f\"best_model_{name}.joblib\")\n",
        "        print(f\"Train scores for {name}: {train_scores}\")\n",
        "        if best_params:\n",
        "            print(\"Best hyperparameters:\")\n",
        "            for k,v in best_params.items(): print(f\"  {k}: {v}\")\n",
        "        if feature_importances is not None: print(\"Top feature importances:\\n\", feature_importances)\n",
        "\n",
        "        # Predict on test_df if provided\n",
        "        if test_df is not None:\n",
        "            test_preds = best.predict(test_df)\n",
        "            submission = pd.DataFrame({\n",
        "                \"PassengerId\": test_df[\"PassengerId\"],\n",
        "                target_col: test_preds\n",
        "            })\n",
        "            submission_file = f\"submission_{name}.csv\"\n",
        "            submission.to_csv(submission_file, index=False)\n",
        "            print(f\"Test predictions saved to {submission_file}\")\n",
        "\n",
        "    elapsed = time.time()-start_time\n",
        "    print(f\"\\nAll models finished in {elapsed/60:.2f} minutes\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ------------------- CLI -------------------\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(description='Auto ML pipeline (multi-model search with Kaggle test prediction)')\n",
        "    parser.add_argument('--train', type=str, default=\"/train.csv\")\n",
        "    parser.add_argument('--test', type=str, default=\"/test.csv\")\n",
        "    parser.add_argument('--target', type=str, default=\"Survived\")\n",
        "    parser.add_argument('--n_iter', type=int, default=25)\n",
        "    parser.add_argument('--cv', type=int, default=5)\n",
        "    parser.add_argument('--max_onehot', type=int, default=12)\n",
        "    args,_ = parser.parse_known_args()\n",
        "\n",
        "    train_df = pd.read_csv(args.train)\n",
        "    test_df = pd.read_csv(args.test) if os.path.exists(args.test) else None\n",
        "\n",
        "    results = run_auto_ml(train_df, test_df=test_df, target_col=args.target, n_iter_search=args.n_iter,\n",
        "                          cv_folds=args.cv, max_onehot_levels=args.max_onehot)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "notebook1359090b1e",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 26502,
          "sourceId": 3136,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31192,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
